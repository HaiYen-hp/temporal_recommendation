2024-03-26 01:55:40,934 - root - INFO - Namespace(data='ml-100k', bs=200, prefix='ml100k_bce', n_degree=35, n_head=4, n_epoch=50, n_layer=3, lr=0.0011, drop_out=0.3, reg=0.2, gpu=1, node_dim=32, time_dim=32, agg_method='attn', attn_mode='prod', time='time', uniform=True, new_node=False, samplerate=1.0, popnegsample=False, timepopnegsample=False, negsampleeval=2000, disencomponents=None)
2024-03-26 01:55:41,719 - model - INFO - Aggregation uses attention model
2024-03-26 01:55:41,721 - model - INFO - Using scaled prod attention
2024-03-26 01:55:41,723 - model - INFO - Using scaled prod attention
2024-03-26 01:55:41,726 - model - INFO - Using scaled prod attention
2024-03-26 01:55:41,726 - model - INFO - Using time encoding
2024-03-26 01:56:00,449 - root - INFO - num of training instances: 80003
2024-03-26 01:56:00,449 - root - INFO - num of batches per epoch: 401
2024-03-26 01:56:00,452 - root - INFO - start 0 epoch
